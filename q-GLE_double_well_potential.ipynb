{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "import scipy.stats\n",
    "from jax.scipy.stats import norm\n",
    "import scipy.optimize\n",
    "import scipy\n",
    "import sympy\n",
    "import symnum\n",
    "import symnum.numpy as snp\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrand\n",
    "import jax.scipy.optimize as jopt\n",
    "from jax.scipy.linalg import cho_solve\n",
    "from jax import jit, vmap, grad, value_and_grad\n",
    "from jax.lax import scan\n",
    "from jax.example_libraries.optimizers import adam\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.config import config\n",
    "config.update('jax_enable_x64', True)\n",
    "config.update('jax_platform_name', 'cpu')\n",
    "import simsde \n",
    "from simsde.operators import v_hat_k, subscript_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[0]: extended space (rough), x[1]: momentum, x[2]:position\n",
    "\n",
    "def drift_position(x, θ):\n",
    "    return snp.array([x[1]])\n",
    "\n",
    "def drift_momentum(x, θ):\n",
    "    D, λ, *_ = θ\n",
    "    # the potential function q -> V(q) is assumed to be V(q) = (q^2 - D)^2 / 4 \n",
    "    return snp.array([- (x[2]**3-D*x[2]) + λ*x[0]])\n",
    "\n",
    "def diff_coeff_rough(x, θ):\n",
    "    *_, σ = θ\n",
    "    return snp.array([[σ]])\n",
    "\n",
    "def drift_rough(x, θ):\n",
    "    D, λ, α, *_ = θ\n",
    "    return snp.array([- λ*x[1] - α*x[0]])\n",
    "\n",
    "def drift_smooth(x, θ):\n",
    "    return snp.concatenate((drift_momentum(x, θ), drift_position(x, θ)))\n",
    "\n",
    "def drift_func(x, θ):\n",
    "    return snp.concatenate((drift_rough(x, θ), drift_smooth(x, θ)))\n",
    "\n",
    "def diff_coeff(x, θ):\n",
    "    *_, σ = θ\n",
    "    return snp.array([[σ], [0], [0]])\n",
    "\n",
    "dim_x = 3\n",
    "dim_s1 = 1\n",
    "dim_s2 = 1\n",
    "dim_r = 1\n",
    "dim_θ = 4 \n",
    "dim_w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast function for weaker step size condition\n",
    "\n",
    "def m_and_Σ_p_3(y, x, θ, t):\n",
    "    dim_r = drift_rough(x, θ).shape[0]\n",
    "    dim_s2 = drift_momentum(x, θ).shape[0]\n",
    "    x_r, x_s_2, x_s_1 = x[:dim_r], x[dim_r : dim_r + dim_s2], x[dim_r + dim_s2 :]\n",
    "    y_r, y_s_2, y_s_1 = y[:dim_r], y[dim_r : dim_r + dim_s2], y[dim_r + dim_s2 :]\n",
    "\n",
    "    # m: standardisation of three components\n",
    "    m = snp.concatenate(\n",
    "        [\n",
    "        (\n",
    "            y_r - x_r - drift_rough(x, θ) * t\n",
    "        )\n",
    "        / snp.sqrt(t), \n",
    "        #\n",
    "        (\n",
    "            y_s_2 - x_s_2 - drift_momentum(x, θ) * t \n",
    "            - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_momentum)(x, θ)* (t**2) / 2\n",
    "        )\n",
    "        / snp.sqrt(t)**3,\n",
    "        # \n",
    "        (\n",
    "            y_s_1 - x_s_1 - drift_position(x, θ) * t \n",
    "            - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position)(x, θ)* (t**2) / 2\n",
    "            - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position))(x, θ) * (t**3)/6\n",
    "        )\n",
    "        / snp.sqrt(t)**5,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    C_r = diff_coeff_rough(x, θ)\n",
    "    C_s2 = snp.array(\n",
    "        [\n",
    "            v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(drift_momentum)(\n",
    "                x, θ\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    C_s1 = snp.array(\n",
    "        [\n",
    "            v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(\n",
    "                v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position)\n",
    "            )(x, θ)\n",
    "        ],\n",
    "    )\n",
    "    Σ_RR = C_r @ C_r.T\n",
    "    Σ_RS2 = C_r @ C_s2.T / 2\n",
    "    Σ_RS1 = C_r @ C_s1.T / 6\n",
    "    Σ_S2S2 = C_s2 @ C_s2.T / 3\n",
    "    Σ_S2S1 = C_s2 @ C_s1.T / 8\n",
    "    Σ_S1S1 = C_s1 @ C_s1.T / 20\n",
    "    Σ = snp.concatenate(\n",
    "        [\n",
    "            snp.concatenate([Σ_RR, Σ_RS2, Σ_RS1], axis=1),\n",
    "            snp.concatenate([Σ_RS2.T, Σ_S2S2, Σ_S2S1], axis=1),\n",
    "            snp.concatenate([Σ_RS1.T, Σ_S2S1.T, Σ_S1S1], axis=1),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    return m, Σ\n",
    "\n",
    "def m_and_Σ_p_4(y, x, θ, t):\n",
    "    dim_r = drift_rough(x, θ).shape[0]\n",
    "    dim_s2 = drift_momentum(x, θ).shape[0]\n",
    "    x_r, x_s_2, x_s_1 = x[:dim_r], x[dim_r : dim_r + dim_s2], x[dim_r + dim_s2 :]\n",
    "    y_r, y_s_2, y_s_1 = y[:dim_r], y[dim_r : dim_r + dim_s2], y[dim_r + dim_s2 :]\n",
    "\n",
    "    # m: standardisation of three components\n",
    "    m = snp.concatenate(\n",
    "        [\n",
    "        (\n",
    "            y_r - x_r - drift_rough(x, θ) * t - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_rough)(x, θ)* t**2 / 2\n",
    "        )\n",
    "        / snp.sqrt(t), \n",
    "        #\n",
    "        (\n",
    "            y_s_2 - x_s_2 - drift_momentum(x, θ) * t \n",
    "            - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_momentum)(x, θ)* t**2 / 2\n",
    "            - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(\n",
    "            v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_momentum)\n",
    "            )(x, θ) * (t**3) / 6\n",
    "        )\n",
    "        / snp.sqrt(t)**3,\n",
    "        # \n",
    "        (\n",
    "            y_s_1 - x_s_1 - drift_position(x, θ) * t \n",
    "            - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position)(x, θ)* t**2 / 2\n",
    "            - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position))(x, θ) * t**3/6\n",
    "            - v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position)))(x, θ) * (t**4) / 24\n",
    "        )\n",
    "        / snp.sqrt(t)**5,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    C_r = diff_coeff_rough(x, θ)\n",
    "    C_s2 = snp.array(\n",
    "        [\n",
    "            v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(drift_momentum)(\n",
    "                x, θ\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    C_s1 = snp.array(\n",
    "        [\n",
    "            v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(\n",
    "                v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position)\n",
    "            )(x, θ)\n",
    "        ],\n",
    "    )\n",
    "    Σ_RR = C_r @ C_r.T\n",
    "    Σ_RS2 = C_r @ C_s2.T / 2\n",
    "    Σ_RS1 = C_r @ C_s1.T / 6\n",
    "    Σ_S2S2 = C_s2 @ C_s2.T / 3\n",
    "    Σ_S2S1 = C_s2 @ C_s1.T / 8\n",
    "    Σ_S1S1 = C_s1 @ C_s1.T / 20\n",
    "    Σ = snp.concatenate(\n",
    "        [\n",
    "            snp.concatenate([Σ_RR, Σ_RS2, Σ_RS1], axis=1),\n",
    "            snp.concatenate([Σ_RS2.T, Σ_S2S2, Σ_S2S1], axis=1),\n",
    "            snp.concatenate([Σ_RS1.T, Σ_S2S1.T, Σ_S1S1], axis=1),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    return m, Σ\n",
    "\n",
    "def sym_Σ_1(x, θ, t):\n",
    "    σ = diff_coeff_rough(x, θ)\n",
    "    L1_mu_R = v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(drift_rough)(x, θ)\n",
    "    L1_mu_S2 = v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(drift_momentum)(x, θ)\n",
    "    L1L0_mu_S2 = v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_momentum))(x, θ) \n",
    "    L1L0_mu_S1 = v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position))(x, θ)\n",
    "    L1L0L0_mu_S1 = v_hat_k(drift_func, diff_coeff_rough, 1, dim_r)(v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(v_hat_k(drift_func, diff_coeff_rough, 0, dim_r)(drift_position)))(x, θ)\n",
    "\n",
    "\n",
    "    Σ_1_RR = snp.array(2*t*σ*L1_mu_R/2)\n",
    "    Σ_1_RS2 = snp.array(t*(σ*L1L0_mu_S2/6 + L1_mu_R*L1_mu_S2/3))\n",
    "    Σ_1_RS1 = snp.array(t*(σ*L1L0L0_mu_S1/24 + L1_mu_R*L1L0_mu_S1/8))\n",
    "    Σ_1_S2S2 = snp.array([2*t*L1_mu_S2*L1L0_mu_S2/8])\n",
    "    Σ_1_S2S1 = snp.array([t*(L1_mu_S2*L1L0L0_mu_S1/30 + L1L0_mu_S2*L1L0_mu_S1/20)])\n",
    "    Σ_1_S1S1 = snp.array([2*t*L1L0_mu_S1*L1L0L0_mu_S1/72])\n",
    "    Σ_1 = snp.concatenate(\n",
    "        [\n",
    "            snp.concatenate([Σ_1_RR, Σ_1_RS2, Σ_1_RS1], axis=1),\n",
    "            snp.concatenate([Σ_1_RS2, Σ_1_S2S2, Σ_1_S2S1], axis=1),\n",
    "            snp.concatenate([Σ_1_RS1, Σ_1_S2S1, Σ_1_S1S1], axis=1),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    return Σ_1\n",
    "\n",
    "def contrast_function_p_2(\n",
    "    drift_func_smooth_1, drift_func_smooth_2, drift_func_rough, diff_coeff_rough):\n",
    "\n",
    "    def one_step_contrast_function(x_t, x_0, θ, t):\n",
    "        dim_x = x_0.shape[0]\n",
    "        m, Σ = m_and_Σ_p_3(x_t, x_0, θ, t) \n",
    "        m, Σ, = sympy.Matrix(m), sympy.Matrix(Σ)\n",
    "        chol_Σ = Σ.cholesky(hermitian=False)\n",
    "        invΣ = Σ.inverse_CH()\n",
    "        \n",
    "        return -(\n",
    "            (m.T @ invΣ @ m)[0, 0]\n",
    "            / 2\n",
    "            + snp.log(chol_Σ.diagonal()).sum()\n",
    "        )\n",
    "\n",
    "    return one_step_contrast_function\n",
    "\n",
    "def contrast_function_p_3(\n",
    "    drift_func_smooth_1, drift_func_smooth_2, drift_func_rough, diff_coeff_rough):\n",
    "\n",
    "    def one_step_contrast_function(x_t, x_0, θ, t):\n",
    "        dim_x = x_0.shape[0]\n",
    "        m, Σ = m_and_Σ_p_3(x_t, x_0, θ, t) \n",
    "        Σ_1 = sym_Σ_1(x_0, θ, t)\n",
    "        m, Σ, Σ_1 = sympy.Matrix(m), sympy.Matrix(Σ), sympy.Matrix(Σ_1)\n",
    "        chol_Σ = Σ.cholesky(hermitian=False)\n",
    "        invΣ = Σ.inverse_CH()\n",
    "        invΣ_Σ_1 = sympy.Matrix(invΣ @ Σ_1)\n",
    "        \n",
    "        return -(\n",
    "            (m.T @ (invΣ - invΣ @ Σ_1 @ invΣ) @ m)[0, 0]\n",
    "            / 2\n",
    "            + snp.log(chol_Σ.diagonal()).sum()\n",
    "            + invΣ_Σ_1.trace()/2\n",
    "        )\n",
    "\n",
    "    return one_step_contrast_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "symolic_log_transition_density_generators = {\n",
    "    'local_gaussian (p = 2)': contrast_function_p_2,\n",
    "    'local_gaussian (p = 3)': contrast_function_p_3,\n",
    "}\n",
    "jax_log_transition_densities = {\n",
    "    key: symnum.numpify(dim_x, dim_x, dim_θ, None, numpy_module=jnp)(\n",
    "        symbolic_transition_density_generator(\n",
    "            drift_position, drift_momentum, drift_rough, diff_coeff_rough\n",
    "        )\n",
    "    )\n",
    "    for key, symbolic_transition_density_generator in \n",
    "    symolic_log_transition_density_generators.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_likelihood_functions(log_transition_density):\n",
    "    @jit\n",
    "    \n",
    "    def log_likelihood_θ(θ, x_seq, t_seq):\n",
    "        log_transition_density_terms = vmap(log_transition_density, (0, 0, None, 0))(\n",
    "            x_seq[1:], x_seq[:-1], θ, t_seq[1:] - t_seq[:-1]\n",
    "        )\n",
    "        return log_transition_density_terms.sum()\n",
    "            \n",
    "    return {'θ': log_likelihood_θ}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_n, step_func = {\n",
    "    \"euler_maruyama\": (\n",
    "        dim_r,\n",
    "        simsde.integrators.euler_maruyama_step(drift_func, diff_coeff),\n",
    "    ),\n",
    "    \"local_gaussian_ii\": (\n",
    "        3*dim_r,\n",
    "        simsde.integrators.hypoelliptic_ii_local_gaussian_step(\n",
    "        drift_func, drift_rough, drift_position, drift_momentum, diff_coeff_rough)\n",
    "    )\n",
    "}[\"local_gaussian_ii\"]\n",
    "\n",
    "jax_step_func = symnum.numpify(dim_x, dim_θ, dim_n, (), numpy_module=jnp)(step_func)\n",
    "\n",
    "@jit\n",
    "def simulate_diffusion(x_0, θ, t_seq, n_seq):\n",
    "    \n",
    "    def step_func(x, n_dt):\n",
    "        n, dt = n_dt\n",
    "        x_next = jax_step_func(x, θ, n, dt)\n",
    "        return x_next, x_next\n",
    "    \n",
    "    _, x_seq = scan(step_func, x_0, (n_seq, t_seq[1:] - t_seq[:-1]))\n",
    "    \n",
    "    return jnp.concatenate((x_0[None], x_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting \n",
    "rng = np.random.default_rng(20230204)\n",
    "dt_simulation = 1e-4  # step size for synthetic data \n",
    "T = 1000  # Time length of data step \n",
    "θ_true = jnp.array([2.0, 1.0, 4.0, 4.0]) # param θ = (D, λ, α, σ) \n",
    "x_0 = jnp.array([0.0, 0.0, 0.0]) # initial value  \n",
    "t_seq_sim = np.arange(int(T / dt_simulation) + 1) * dt_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_complete_maximum_likelihood_estimates(\n",
    "    log_likelihood, t_seq, x_seqs, θ_0, optimizer=adam, n_steps=8000, step_size=1e-1\n",
    "):\n",
    "    optimizer_init, optimizer_update, optimizer_get_params = optimizer(step_size)\n",
    "    \n",
    "    @jit \n",
    "    def optimizer_step(step_index, state, x_seq, t_seq):\n",
    "        value, grad = value_and_grad(log_likelihood[\"θ\"])(\n",
    "            optimizer_get_params(state), x_seq, t_seq\n",
    "        )\n",
    "        state = optimizer_update(step_index, -grad, state)\n",
    "        return value, state\n",
    "\n",
    "    state = optimizer_init(θ_0)\n",
    "\n",
    "    for s in range(n_steps):\n",
    "        _, state = optimizer_step(s, state, x_seqs, t_seq)\n",
    "        # print(optimizer_get_params(state))\n",
    "        \n",
    "    return optimizer_get_params(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the observations -- Start\n",
      "Compute the observations -- End\n",
      "Optimisation Complete Observation Adam -- Start local_gaussian (p = 2) 0.005\n",
      "Optimisation Complete Observation Adam -- End local_gaussian (p = 2) 0.005\n",
      "[2.00005513 1.000045   4.02249715 3.99186078]\n",
      "(Array(-224156.70445711, dtype=float64), Array([-5.17262322e-09, -1.76919457e-08,  2.17159624e-13,  3.62162491e-07],      dtype=float64))\n",
      "0\n",
      "Optimisation Complete Observation Adam -- Start local_gaussian (p = 3) 0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m get_log_likelihood_functions(log_transition_density)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimisation Complete Observation Adam -- Start\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m, dt_obs)\n\u001b[0;32m---> 32\u001b[0m complete_adam \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_complete_maximum_likelihood_estimates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_seq_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_seq_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mθ_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimisation Complete Observation Adam -- End\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m, dt_obs)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(complete_adam)\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mcompute_complete_maximum_likelihood_estimates\u001b[0;34m(log_likelihood, t_seq, x_seqs, θ_0, optimizer, n_steps, step_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m state \u001b[38;5;241m=\u001b[39m optimizer_init(θ_0)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps):\n\u001b[0;32m---> 17\u001b[0m     _, state \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_seqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# print(optimizer_get_params(state))\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer_get_params(state)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/jax/example_libraries/optimizers.py:120\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(data, xs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m# The implementation here basically works by flattening pytrees. There are two\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m# levels of pytrees to think about: the pytree of params, which we can think of\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m# as defining an \"outer pytree\", and a pytree produced by applying init_fun to\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m# each leaf of the params pytree, which we can think of as the \"inner pytrees\".\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m# Since pytrees can be flattened, that structure is isomorphic to a list of\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m# lists (with no further nesting).\u001b[39;00m\n\u001b[1;32m    115\u001b[0m OptimizerState \u001b[39m=\u001b[39m namedtuple(\u001b[39m\"\u001b[39m\u001b[39mOptimizerState\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m                             [\u001b[39m\"\u001b[39m\u001b[39mpacked_state\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtree_def\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msubtree_defs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    117\u001b[0m register_pytree_node(\n\u001b[1;32m    118\u001b[0m     OptimizerState,\n\u001b[1;32m    119\u001b[0m     \u001b[39mlambda\u001b[39;00m xs: ((xs\u001b[39m.\u001b[39mpacked_state,), (xs\u001b[39m.\u001b[39mtree_def, xs\u001b[39m.\u001b[39msubtree_defs)),\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mlambda\u001b[39;00m data, xs: OptimizerState(xs[\u001b[39m0\u001b[39m], data[\u001b[39m0\u001b[39m], data[\u001b[39m1\u001b[39m]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    123\u001b[0m Array \u001b[39m=\u001b[39m Any\n\u001b[1;32m    124\u001b[0m Params \u001b[39m=\u001b[39m Any  \u001b[39m# Parameters are arbitrary nests of `jnp.ndarrays`.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_sampling = 100\n",
    "seed = 20231024\n",
    "\n",
    "contrast_type_items = {\n",
    "    0: 'local_gaussian (p = 2)',\n",
    "    1: 'local_gaussian (p = 3)',\n",
    "}\n",
    "\n",
    "D_sample_complete = np.empty((2, num_sampling))\n",
    "λ_sample_complete = np.empty((2, num_sampling))\n",
    "α_sample_complete = np.empty((2, num_sampling))\n",
    "σ_sample_complete = np.empty((2, num_sampling))\n",
    "\n",
    "dt_obs_items = [0.005]\n",
    "for item_dt in range(len(dt_obs_items)):\n",
    "    dt_obs = dt_obs_items[item_dt]  # step size for the observation \n",
    "    sub_interval = int(dt_obs/dt_simulation)\n",
    "    for k in range(num_sampling):\n",
    "        print(\"Compute the observations -- Start\")\n",
    "        rng = np.random.default_rng(seed)\n",
    "        n_seqs = rng.standard_normal((t_seq_sim.shape[0] - 1, dim_n))\n",
    "        x_seqs_sim = simulate_diffusion(x_0, θ_true, t_seq_sim, n_seqs)\n",
    "        x_seq_obs = x_seqs_sim[::sub_interval]\n",
    "        print(\"Compute the observations -- End\")\n",
    "\n",
    "        for key, type in contrast_type_items.items():\n",
    "            t_seq_obs = t_seq_sim[::sub_interval]\n",
    "            θ_0 = jnp.array([1.0, 1.0, 1.0, 1.0])\n",
    "            log_transition_density = jax_log_transition_densities[type]\n",
    "            log_likelihood = get_log_likelihood_functions(log_transition_density)\n",
    "            print(\"Optimisation Complete Observation Adam -- Start\", type, dt_obs)\n",
    "            complete_adam = compute_complete_maximum_likelihood_estimates(log_likelihood, t_seq_obs, x_seq_obs, θ_0)\n",
    "            print(\"Optimisation Complete Observation Adam -- End\", type, dt_obs)\n",
    "            print(complete_adam)\n",
    "            print(value_and_grad(log_likelihood[\"θ\"])(complete_adam, x_seq_obs, t_seq_obs))\n",
    "            print(k)\n",
    "            D_sample_complete[key, k] = complete_adam[0]\n",
    "            λ_sample_complete[key, k] = complete_adam[1]\n",
    "            α_sample_complete[key, k] = complete_adam[2]\n",
    "            σ_sample_complete[key, k] = complete_adam[3]\n",
    "        \n",
    "        seed += 1\n",
    "    \n",
    "    # record in a csv file \n",
    "    for key, type in contrast_type_items.items():\n",
    "        f = open(f'MLE_non-linear_final_{type}=T_{T}_dt_obs_{dt_obs}_dt_sim_{dt_simulation}.csv', 'w')\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(D_sample_complete[key,:])\n",
    "        writer.writerow(λ_sample_complete[key,:])\n",
    "        writer.writerow(α_sample_complete[key,:])\n",
    "        writer.writerow(σ_sample_complete[key,:])\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
